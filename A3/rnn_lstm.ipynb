{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try COLAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import google.colab\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    !pip3 install torch matplotlib torchmetrics scikit-image segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence # for padding data\n",
    "\n",
    "import pandas as pd # for making csv file\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import wandb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Support?\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using the GPU\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"Using the CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a dataset of sequences containing characters 'a', 'b', and 'c' in order\n",
    "def gen_data(N=1000, min_len=3, max_len=20) -> list:\n",
    "    \"\"\"Generates a dataset of sequences containing characters 'a', 'b', and 'c' in order.\n",
    "    Parameters: N: int, number of sequences to generate\n",
    "                min_len: int, minimum length of a sequence\n",
    "                max_len: int, maximum length of a sequence\n",
    "    Returns: list of strings, each string is a sequence of characters 'a', 'b', and 'c' in order\"\"\"\n",
    "    dataset = []\n",
    "    max_member = max_len // 3 # three times this number is less than max_len\n",
    "    min_member = min_len // 3 # three times this number is less than min_len\n",
    "    if min_len < 3:\n",
    "        min_len = 3\n",
    "        print(\"Minimum length must be at least 3. Setting min_len to 3.\")\n",
    "    if max_len > 1000:\n",
    "        max_len = 1000\n",
    "        print(\"Maximum length must be at most 1000. Setting max_len to 1000.\")\n",
    "\n",
    "    for n in range(N):\n",
    "        if n % 4 == 0: # 25% of the time add actual member of formal language family\n",
    "            length = random.randint(min_member, max_member)\n",
    "            sequence = 'a' * length + 'b' * length + 'c' * length\n",
    "            dataset.append(sequence)\n",
    "        else:\n",
    "            length = random.randint(min_len-3, max_len-3)  # Random sequence length between 3 and (20-3 = 17). 3 is the smallest possible length for a sequence to be in the language\n",
    "            counts = [1, 1, 1] # Initialize counts for 'a', 'b', and 'c'. Will have at least one of each letter.\n",
    "\n",
    "            # Distribute the length among a, b, and c\n",
    "            for i in range(length):\n",
    "                counts[random.randint(0, 2)] += 1\n",
    "\n",
    "            # Ensure alphabetical order and create the sequence\n",
    "            sequence = 'a' * counts[0] + 'b' * counts[1] + 'c' * counts[2]\n",
    "            dataset.append(sequence)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for labels and encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "def get_labels(data, vebrose=False):\n",
    "    y = torch.zeros(len(data))\n",
    "    for i, sequence in enumerate(data):\n",
    "        if sequence == 'a'*(len(sequence)//3) + 'b'*(len(sequence)//3) + 'c'*(len(sequence)//3):\n",
    "            y[i] = 1\n",
    "    if vebrose:\n",
    "        print(f\"Number of sequences in the language: {y.sum()}\")\n",
    "        print(f\"Number of sequences not in the language: {len(y) - y.sum()}\")\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a one-hot encoding of the sequences and a labels tensor\n",
    "def one_hot_encode(sequence):\n",
    "    encoded = torch.zeros(len(sequence), 3)\n",
    "    for i, char in enumerate(sequence):\n",
    "        encoded[i, 'abc'.index(char)] = 1\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(N, min_len=3, max_len=20, split=False):\n",
    "    \"\"\"\n",
    "    Generates a dataset of sequences containing characters 'a', 'b', and 'c' in order.\n",
    "    One-hot encodes, pads, and creates labels for the dataset.\n",
    "    Parameters: N: int, number of sequences to generate\n",
    "                min_len: int, minimum length of a sequence\n",
    "                max_len: int, maximum length of a sequence\n",
    "                split: bool, whether to split the dataset into train and test sets\n",
    "    Returrns: TensorDataset, list of sequencese if split=False\n",
    "                Tuple(TensorDataset, TensorDataset), list of sequences if split=True\n",
    "    \"\"\"\n",
    "    sequences = gen_data(N, min_len, max_len)\n",
    "    length_tensor = torch.tensor([len(s) for s in sequences])\n",
    "    encoded_sequences = [one_hot_encode(sequence) for sequence in sequences]\n",
    "    padded_sequences = pad_sequence(encoded_sequences, batch_first=True)\n",
    "    y = get_labels(sequences, vebrose=True) # change verbose to False to suppress output\n",
    "    if split: # split into train and test sets\n",
    "        train_size = int(0.8 * N) # 80/20 train/test split\n",
    "        train_data = padded_sequences[:train_size]\n",
    "        test_data = padded_sequences[train_size:]\n",
    "        train_lengths = length_tensor[:train_size]\n",
    "        test_lengths = length_tensor[train_size:]\n",
    "        train_y = y[:train_size]\n",
    "        test_y = y[train_size:]\n",
    "        train_dataset = TensorDataset(train_data, train_y, train_lengths)\n",
    "        test_dataset = TensorDataset(test_data, test_y, test_lengths)\n",
    "        return train_dataset, test_dataset, sequences\n",
    "    dataset = TensorDataset(padded_sequences, y, length_tensor)\n",
    "    return dataset, sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset, sequences = get_dataset(1000, 3, 20, split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        # x -> (batch_length, seq_length, input_size/vocab_size)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        # Gets a padded sequence as input\n",
    "        packed_input = pack_padded_sequence(input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, _ = self.rnn(packed_input)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = out[range(len(out)), lengths-1, :]\n",
    "        # The shape changes from [batch_size, max_seq_length, hidden_size] to [batch_size, hidden_size]\n",
    "        # by selecting the output if last valid timestep for each sequence in the batch\n",
    "        # which reduces the second dimension (sequence length) by selecting specific indices for each sequence in the batch.\n",
    "        out = self.fc(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM Model Definition\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input, lengths):\n",
    "        packed_input = pack_padded_sequence(input, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        packed_out, (hn, cn) = self.lstm(packed_input)\n",
    "        out, _ = pad_packed_sequence(packed_out, batch_first=True)\n",
    "        out = out[range(len(out)), lengths-1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "input_size =  3 # 'a' 'b' 'c'\n",
    "num_classes = 1 # binary classification\n",
    "hidden_size = 30 # hyperparameter; can be tuned\n",
    "num_layers = 1 # hyperparameter; can be tuned\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # \"hyperparameter\" (maybe BCE without LogitsLoss is better?)\n",
    "learning_rate = 0.005 # hyperparameter; can be tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=learning_rate) # SGD (vanishing gradiant midigation)\n",
    "\n",
    "# Training loop RNN\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data, labels, lengths in train_loader:\n",
    "        data, labels, lengths = data.to(device), labels.to(device), lengths.to('cpu')\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = rnn(data, lengths)\n",
    "        loss = criterion(outputs.squeeze(), labels.float()) # BCEWithLogitsLoss expects 1D input, output from RNN is 2D\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop LSTM\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for data, labels, lengths in train_loader:\n",
    "        data, labels, lengths = data.to(device), labels.to(device), lengths.to('cpu')\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = lstm(data, lengths)\n",
    "        loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make dataset with labels to csv\n",
    "# df = pd.DataFrame(sequences)\n",
    "# df['label'] = get_labels(sequences)\n",
    "# df.to_csv('formal_language.csv', index=False)\n",
    "\n",
    "# # Instantiate a WandB run\n",
    "# wandb.login()\n",
    "# run = wandb.init(project=\"formal_language_rnn_lstm\")\n",
    "\n",
    "# # Create an artifact for data\n",
    "# artifact = wandb.Artifact(\"formal_language_data\", type=\"dataset\") \n",
    "# artifact.add_file(\"formal_language.csv\") \n",
    "# run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep config\n",
    "sweep_config = {\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"name\": \"loss\", \"goal\": \"minimize\"},\n",
    "    \"parameters\": {\n",
    "        \"model\": { \"values\": [\"RNN\", \"LSTM\"] },\n",
    "        \"epochs\": {\"values\": [10, 20] },    \n",
    "        \"optimizer\": { \"values\": [\"SGD\", \"Adam\"] },\n",
    "        \"hidden_size\": {\n",
    "            \"values\": [2, 20, 50]\n",
    "        },\n",
    "        \"num_layers\": {\n",
    "            \"values\": [1, 2]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"values\": [0.001, 0.01]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config=None):\n",
    "    with wandb.init(project=\"formal_language_rnn_lstm\", config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        # Get hyperparameters\n",
    "        hidden_size = config.hidden_size\n",
    "        num_layers = config.num_layers\n",
    "        learning_rate = config.learning_rate\n",
    "        num_epochs = config.epochs\n",
    "\n",
    "        # Input size and number of classes\n",
    "        num_classes = 1 # binary classification\n",
    "        input_size = 3 # 'a' 'b' 'c'\n",
    "\n",
    "        # Set criterion\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # Get model\n",
    "        if config.model == \"RNN\":\n",
    "            model = RNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "        else:\n",
    "            model = LSTM(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "        \n",
    "        # Get optimizer\n",
    "        if config.optimizer == \"SGD\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        else:\n",
    "            optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        wandb.watch(model, criterion, log=\"all\")\n",
    "\n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            for data, labels, lengths in train_loader:\n",
    "                data, labels, lengths = data.to(device), labels.to(device), lengths.to('cpu')\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(data, lengths)\n",
    "                loss = criterion(outputs.squeeze(), labels.float())\n",
    "\n",
    "                # Backward and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "            if (epoch+1) % 10 == 0:\n",
    "                wandb.log({\"epoch\": epoch+1, \"loss\": loss.item()})\n",
    "            if (epoch+1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "        print(\"Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sweep_id\n",
    "# sweep_id = wandb.sweep(sweep_config, project=\"formal_language_rnn_lstm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sweep\n",
    "# wandb.agent(sweep_id, function=train, count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_evaluation(model, loader):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for data, label, lengths in loader:\n",
    "            data, label, lengths = data.to(device), label.to(device), lengths.to('cpu')\n",
    "\n",
    "            # Get the model's predictions\n",
    "            output = model(data, lengths)\n",
    "            pred = torch.round(torch.sigmoid(output)) # Sigmoid to get probabilities, round to get binary predictions\n",
    "\n",
    "            y_true.extend(label.tolist())\n",
    "            y_pred.extend(pred.tolist())\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=1)\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report F1 Score (and accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_accuracy, rnn_f1 = report_evaluation(rnn, test_loader)\n",
    "lstm_accuracy, lstm_f1 = report_evaluation(lstm, test_loader)\n",
    "\n",
    "\n",
    "print(f'RNN Test Accuracy: {rnn_accuracy*100:.2f}%')\n",
    "print(f'RNN F1 Score: {rnn_f1:.2f}')\n",
    "print(f'LSTM Test Accuracy: {lstm_accuracy*100:.2f}%')\n",
    "print(f'LSTM F1 Score: {lstm_f1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalization and Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new test data of len 21 to 30 to see how well the models generalize\n",
    "longSeq_dataset, longSeq_sequences = get_dataset(1000, min_len=21, max_len=30, split=False)\n",
    "longSeq_loader = DataLoader(longSeq_dataset, batch_size=len(longSeq_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_to_scores(model, loader):\n",
    "    \"\"\"\n",
    "    Get the F1 score of a model for each sequence length in the test set\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    length_to_true_pred = {}\n",
    "    with torch.no_grad():\n",
    "        for data, label, lengths in loader:\n",
    "            data, label, lengths = data.to(device), label.to(device), lengths.to('cpu')\n",
    "\n",
    "            # Get the model's predictions\n",
    "            output = model(data, lengths)\n",
    "            pred = torch.round(torch.sigmoid(output)) # Sigmoid to get probabilities, round to get binary predictions\n",
    "            \n",
    "            for i, length in enumerate(lengths):\n",
    "                if length not in length_to_true_pred:\n",
    "                    length_to_true_pred[length.item()] = {'true': [], 'pred': []}\n",
    "\n",
    "                length_to_true_pred[length.item()]['true'].append(label[i].item())\n",
    "                length_to_true_pred[length.item()]['pred'].append(pred[i].item())\n",
    "\n",
    "    # sort list\n",
    "    length_to_true_pred = dict(sorted(length_to_true_pred.items()))\n",
    "        \n",
    "    # check if all predictions are correct\n",
    "    for length in length_to_true_pred:\n",
    "        if length_to_true_pred[length]['true'] == length_to_true_pred[length]['pred']:\n",
    "            print(f\"All predictions are correct for sequences of length {length}\")\n",
    "\n",
    "    length_to_f1 = {}\n",
    "    length_to_accuracy = {}\n",
    "    for length, values in length_to_true_pred.items():\n",
    "        f1 = f1_score(values['true'], values['pred'], zero_division=1) # zero_division=1 to avoid division by 0\n",
    "        accuracy = accuracy_score(values['true'], values['pred'])\n",
    "        length_to_f1[length] = f1\n",
    "        length_to_accuracy[length] = accuracy\n",
    "\n",
    "\n",
    "    return length_to_f1 , length_to_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_accuracy, rnn_f1 = report_evaluation(rnn, longSeq_loader)\n",
    "lstm_accuracy, lstm_f1 = report_evaluation(lstm, longSeq_loader)\n",
    "\n",
    "\n",
    "print(f'RNN Test Accuracy: {rnn_accuracy*100:.2f}%')\n",
    "print(f'RNN F1 Score: {rnn_f1:.2f}')\n",
    "print(f'LSTM Test Accuracy: {lstm_accuracy*100:.2f}%')\n",
    "print(f'LSTM F1 Score: {lstm_f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot F1 scores for each sequence length for RNN and LSTM bar plot side by side\n",
    "rnn_f1, rnn_accuracy = length_to_scores(rnn, longSeq_loader)\n",
    "lstm_f1, lstm_accuracy= length_to_scores(lstm, longSeq_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot Accuracy scores side by side using seaborn in w/ barplot same plot\n",
    "rnn_df = pd.DataFrame(list(rnn_accuracy.items()), columns=['Length', 'Accuracy'])\n",
    "rnn_df['Model'] = 'RNN'\n",
    "lstm_df = pd.DataFrame(list(lstm_accuracy.items()), columns=['Length', 'Accuracy'])\n",
    "lstm_df['Model'] = 'LSTM'\n",
    "df = pd.concat([rnn_df, lstm_df])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=df, x='Length', y='Accuracy', hue='Model', alpha=0.9)\n",
    "plt.title('Accuracy by Sequence Length')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
